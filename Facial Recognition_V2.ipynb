{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954f029d",
   "metadata": {},
   "source": [
    "## Face recognition machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199f6db",
   "metadata": {},
   "source": [
    "### Import the require facial_recognition libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54689866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import face_recognition\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "#from goto import goto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364449e1",
   "metadata": {},
   "source": [
    "### To create dictionaries of id, names and face encodings of embedded faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c133be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dictt={}\n",
    "embed_dictt = {}\n",
    "ref_id = 'Default'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559310f1",
   "metadata": {},
   "source": [
    "### Create the name and the reference id of the first face to be embedded and recognised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2efb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name: Kim Rui\n",
      "Enter id: 1\n",
      "Enter another name and id? y/n \n",
      "y\n",
      "Enter name: Elon Musk\n",
      "Enter id: 2\n",
      "Enter another name and id? y/n \n",
      "n\n",
      "Reference dictionary of names and id: {'1': 'Kim Rui', '2': 'Elon Musk'}\n"
     ]
    }
   ],
   "source": [
    "#Create and add new keys and items to dictionary {ref_id: 'name'}\n",
    "name=input(\"Enter name: \")\n",
    "ref_id=input(\"Enter id: \")\n",
    "while True:\n",
    "    if ref_id in ref_dictt.keys(): #see if the key entered has been taken.\n",
    "        print(\"id entered has been taken. Please enter a new id.\")\n",
    "        ref_id=input(\"Enter id: \")\n",
    "    else:\n",
    "        ref_dictt[ref_id]=name\n",
    "        break\n",
    "        \n",
    "while True:        \n",
    "    response=input(\"Enter another name and id? y/n \\n\").lower().strip()\n",
    "    if response == 'y':\n",
    "        name=input(\"Enter name: \")\n",
    "        ref_id=input(\"Enter id: \")\n",
    "        while True:\n",
    "            if ref_id in ref_dictt.keys(): #see if the key entered has been taken.\n",
    "                print(\"id entered has been taken. Please enter a new id.\")\n",
    "                ref_id=input(\"Enter id: \")\n",
    "            else:\n",
    "                ref_dictt[ref_id]=name\n",
    "                break\n",
    "    elif response == 'n':\n",
    "        break\n",
    "    else:\n",
    "        print(\"Please enter y or n\")\n",
    "        continue\n",
    "print(f\"Reference dictionary of names and id: {ref_dictt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd069683",
   "metadata": {},
   "source": [
    "### Open webcam and take specified number of photos of the target person as input and create its embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e0052e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning the face of Kim Rui.\n",
      "Turning off camera.\n",
      "Camera off.\n",
      "Program ended.\n",
      "Embedding process completed.\n"
     ]
    }
   ],
   "source": [
    "Activation1 = True\n",
    "Activation2 = True\n",
    "Button_press = 0\n",
    "id_list = list(ref_dictt.keys())\n",
    "i = 0\n",
    "\n",
    "while Activation1:\n",
    "    \n",
    "    webcam = cv2.VideoCapture(0) #Opens a camera for video capturing. 0 for first camera input.\n",
    "    print(\"Scanning the face of {}.\".format(ref_dictt[id_list[i]]))\n",
    "    \n",
    "    while Activation2:\n",
    "        \n",
    "        #Check read of cam\n",
    "        check, frame = webcam.read() #Returns first a boolean (check) indicating whether the read was successful, and then the image(frame) itself (which will be empty if the return value was False). \n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1] #small_frame has three dimensions - height, width, colour (255,255,0)\n",
    "    \n",
    "        #Detect coordinates of face in frame\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame) # Return a list of tuples of found face locations in css (top, right, bottom, left) order.\n",
    "        \n",
    "        #Map all coordinates of face location to face tracking rectangle\n",
    "        for top_s, right, bottom, left in face_locations: # face_locations = a tuple of (top_s, right, bottom, left)\n",
    "            top_s *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "            cv2.rectangle(frame, (left, top_s), (right, bottom), (0, 0, 255), 2) #frame the face with a rectangle. cv2.rectangle(image, start_point, end_point, color, thickness) color=(0,0,255)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)  #fill the area bound with red colour\n",
    "\n",
    "            #To displace the face tracking rectangle and the number of scan completed.\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            text = 'Scan ' + str(Button_press) + f' of {ref_dictt[id_list[i]]}'\n",
    "            cv2.putText(frame, text, (left + 6, bottom - 6), font, 0.6, (255, 255, 255), 1)\n",
    "       \n",
    "        # To display the instructions on window.\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        text = 'Press \"s\" to scan/ \"q\" to scan next face/'\n",
    "        cv2.putText(frame, text, (15, 15), font, 0.6, (0, 0, 255), 1)\n",
    "        # To display the instructions on window.\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        text = '\"c\" to close the program.'\n",
    "        cv2.putText(frame, text, (15, 35), font, 0.6, (0, 0, 255), 1)\n",
    "        \n",
    "        cv2.imshow(\"Embedding Process\", frame) #cv2.imshow(window_name, image)\n",
    "        \n",
    "        #To capture face and translate face pixel to face encodings for each frame captured on webcam.\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('s'): #Press 's' to capture the images of the target person. ord('q') returns the Unicode code point of q which is 8 bits of value betwen 0 and 255.\n",
    "            Button_press += 1\n",
    "            \n",
    "            if face_locations != []: #some faces are detected and so proceed to encode the faces.\n",
    "                try:\n",
    "                    face_encoding = face_recognition.face_encodings(frame)[0] #Given an image, return the 128-dimension face encoding for each face in the image.\n",
    "                except:\n",
    "                    break\n",
    "                \n",
    "                if ref_id in embed_dictt: #check if ref_id of target face is store on embedded dictionary\n",
    "                    embed_dictt[id_list[i]] += [face_encoding]\n",
    "                else:\n",
    "                    embed_dictt[id_list[i]] = [face_encoding]\n",
    "                #webcam.release()\n",
    "                #cv2.waitKey(1)\n",
    "                #cv2.destroyAllWindows() #release the camera and shut the display window after every image taken.\n",
    "                break\n",
    "            \n",
    "        #Scan the next face if 'q' button is pressed.\n",
    "        elif key == ord('q'):\n",
    "            Button_press = 0\n",
    "            i += 1\n",
    "            if i >= len(id_list): #no more faces to scan\n",
    "                print(\"Turning off camera.\")\n",
    "                webcam.release()\n",
    "                print(\"Camera off.\")\n",
    "                print(\"Program ended.\")\n",
    "                cv2.destroyAllWindows()\n",
    "                Activation2 = False\n",
    "                Activation1 = False\n",
    "                break\n",
    "            print(\"Scanning the face of {}.\".format(ref_dictt[id_list[i]]))\n",
    "                  \n",
    "        #To turn off the camera if 'c' button was pressed.\n",
    "        elif key == ord('c'): \n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            Activation2 = False\n",
    "            Activation1 = False\n",
    "            break\n",
    "    \n",
    "print(\"Embedding process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2534bfb",
   "metadata": {},
   "source": [
    "### Transfer dictionaries of names and face encoding to respective lists of names and face encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1edd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two lists, one to store ref_id and other for respective embedding:\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "for id_ , list_ in embed_dictt.items():\n",
    "    for item_ in list_: #for list_, there will be num_of_takes of items for each face with ref_id/id_\n",
    "        known_face_encodings +=[item_] \n",
    "        known_face_names += [id_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c9f63",
   "metadata": {},
   "source": [
    "### Recognizing faces on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e632137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the webcam to recognize the person:\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = video_capture.read()\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "    \n",
    "    #translate the face and location of face in the frame into encodings \n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations) #Return a list of 128-dimensional face encodings (one for each face in the image). Face locations which are the bounding boxes of each face are optional.\n",
    "    face_names = []\n",
    "        \n",
    "    for face_encoding in face_encodings:\n",
    "        #Comparing incoming face encodings with the embedded face encoding\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding) #Return a list of True/False values indicating which known_face_encodings match the face encoding to check\n",
    "        name = 'Unknown'\n",
    "            \n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding) #Compare a list of face encodings stored in embed_dictt against a candidate encoding from new camera capture to see if they match. Returns: A numpy ndarray with the distance for each face in the same order as the ‘faces’ array\n",
    "        best_match_index = np.argmin(face_distances) #Return index of smallest face_distances\n",
    "            \n",
    "        if matches[best_match_index]: #Only True match will trigger this if statement.\n",
    "            name = known_face_names[best_match_index] #name is assigned the ref_id\n",
    "        face_names.append(name)\n",
    "    \n",
    "    for (top_s, right, bottom, left), ref_id in zip(face_locations, face_names): # zip(face_locations, face_names) = a tuple of ( (top_s, right, bottom, left), name )\n",
    "        top_s *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "        cv2.rectangle(frame, (left, top_s), (right, bottom), (0, 0, 255), 2) #frame the face with a rectangle. cv2.rectangle(image, start_point, end_point, color, thickness) color=(0,0,255)\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)  #fill the area bound with red colour\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        \n",
    "        if ref_id == 'Unknown':\n",
    "            cv2.putText(frame, 'Unknown', (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1) #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "        else:\n",
    "            cv2.putText(frame, ref_dictt[ref_id], (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1) #fill the area bound with red colour\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(frame, 'Press \"c\" to close the program.', (15, 15), font, 0.6, (0, 0, 255), 1)\n",
    "    cv2.imshow('Recognizing', frame) #cv2.imshow(window_name, image)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        break\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb029cd",
   "metadata": {},
   "source": [
    "### Explanation for some codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92828f",
   "metadata": {},
   "source": [
    "###  \n",
    "cv2.waitKey(1) & 0xFF:\n",
    "\n",
    "Wait 1 ms for key press and it will continue to refresh and read frame from your webcam using .read(). If user press, 'q' then waitKey return DECIMAL VALUE of 'q' is 113. In Binary, It is expressed as 0b01110001. \n",
    "\n",
    "Next, AND operator is excuted with two inputs are 0b01110001 and 0xFF (0b11111111). 0b01110001 AND 0b11111111 = 0b01110001. The exact result is binary number of q.\n",
    "                 \n",
    "Second, compare value of left expression 0b01110001 with ord('q'). \n",
    "Clearly, these values is the same as another value. And final result is break is invoked. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485848c",
   "metadata": {},
   "source": [
    "### Useful site\n",
    "https://pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/\n",
    "https://face-recognition.readthedocs.io/en/latest/face_recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131359f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
